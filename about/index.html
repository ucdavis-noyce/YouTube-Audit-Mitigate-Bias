<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>YouTube, The Great Radicalizer?</title>
    <script>const PAGE_NAME = 'about';</script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.3/css/bulma.min.css">
    <link rel="stylesheet" href="/css/styles.css">
    <link rel="apple-touch-icon" sizes="180x180" href="/favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon/favicon-16x16.png">
    <link rel="manifest" href="/favicon/site.webmanifest">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-187WWF7R0T"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-187WWF7R0T');
    </script>
</head>

<body>

    <header class="section">
        <div class="container is-max-desktop">
            <h1 class="title mb-2 has-text-centered">
                Auditing <span class="has-text-danger">YouTube's</span> Recommendation System
            </h1>
            <br>
            <div class="has-text-centered" id="nav">
                <a href="/about" class="button has-text-danger border-none">About</a>
                <a href="https://www.pnas.org/doi/abs/10.1073/pnas.2213020120" target="_blank" class="button has-text-danger border-none">Paper</a>
                <!-- <a href="https://arxiv.org/pdf/2203.10666.pdf" target="_blank" class="button has-text-danger border-none">Preprint</a> -->
                <!-- <a href="/explore" class="button has-text-danger border-none">Explore</a> -->
                <a href="/code" class="button has-text-danger border-none">Code</a>
                <a href="/faqs" class="button has-text-danger border-none">FAQs</a>
            </div>
        </div>
    </header>

    <script>
        const nav = document.getElementById('nav');
        const navItems = nav.getElementsByTagName('a');
        for (const navItem of navItems) {
            if (navItem.innerHTML.toLowerCase().includes(PAGE_NAME)) {
                navItem.classList.add('is-danger');
                navItem.classList.remove('has-text-danger');
            }
        }
    </script>

    <article class="section">
        <div class="container is-max-desktop">
            <h2 class="subtitle has-text-danger has-text-weight-bold">Abstract</h2>
            <p class="has-text-justified">
                Algorithms of social media platforms are often criticized for recommending ideologically congenial and radical content to their users. Despite these concerns, evidence on such filter bubbles and rabbit holes of radicalization is inconclusive. We conduct an audit of the platform using 100,000 sock puppets that allow us to systematically and at scale isolate the influence of the algorithm in recommendations. We test 1) whether recommended videos are congenial with regard to users’ ideology, especially deeper in the watch trail and whether 2) recommendations deeper in the trail become progressively more extreme and come from problematic channels. We find that YouTube’s algorithm recommends congenial content to its partisan users, although some moderate and cross-cutting exposure is possible and that congenial recommendations increase deeper in the trail for right-leaning users. We do not find meaningful increases in ideological extremity of recommendations deeper in the trail, yet we show that a growing proportion of recommendations comes from channels categorized as problematic (e.g., “IDW,” “Alt-right,” “Conspiracy,” and “QAnon”), with this increase being most pronounced among the very-right users. Although the proportion of these problematic recommendations is low (max of 2.5%), they are still encountered by over 36.1% of users and up to 40% in the case of very-right users.
            </p>
        </div>
    </article>
    
    <article class="section">
        <div class="container is-max-desktop">
            <h2 class="subtitle has-text-danger has-text-weight-bold">People</h2>
            <div class="is-flex author-list is-justify-content-space-around is-flex-wrap-wrap">

                <div class="is-flex is-flex-direction-column is-align-items-center has-text-centered">
                    <figure class="image is-128x128">
                        <img class="is-rounded square-128x128" src="/img/haroon.jpg">
                    </figure>
                    <a href="https://muhammadharoon.xyz" target="_blank" class="is-size-6 mt-3">Muhammad Haroon</a>
                </div>

                <div class="is-flex is-flex-direction-column is-align-items-center has-text-centered">
                    <figure class="image is-128x128">
                        <img class="is-rounded square-128x128" target="_blank" src="/img/magdalena.jpg">
                    </figure>
                    <a href="https://communication.ucdavis.edu/people/mwojcie1" class="is-size-6 mt-3">Magdalena Wojcieszak</a>
                </div>

                <div class="is-flex is-flex-direction-column is-align-items-center has-text-centered">
                    <figure class="image is-128x128">
                        <img class="is-rounded square-128x128" src="/img/anshuman.jpg">
                    </figure>
                    <a href="https://www.anshumanc.com/" target="_blank" class="is-size-6 mt-3">Anshuman Chhabra</a>
                </div>


                <div class="is-flex is-flex-direction-column is-align-items-center has-text-centered">
                    <figure class="image is-128x128">
                        <img class="is-rounded square-128x128" src="/img/xin.jpg">
                    </figure>
                    <a href="https://xinliu.engineering.ucdavis.edu/" target="_blank" class="is-size-6 mt-3">Xin Liu</a>
                </div>


                <div class="is-flex is-flex-direction-column is-align-items-center has-text-centered">
                    <figure class="image is-128x128">
                        <img class="is-rounded square-128x128" src="/img/prasant.jpg">
                    </figure>
                    <a href="https://faculty.engineering.ucdavis.edu/mohapatra/" target="_blank" class="is-size-6 mt-3">Prasant Mohapatra</a>
                </div>


                <div class="is-flex is-flex-direction-column is-align-items-center has-text-centered">
                    <figure class="image is-128x128">
                        <img class="is-rounded square-128x128" src="/img/zubair.jpg">
                    </figure>
                    <a href="https://web.cs.ucdavis.edu/~zubair/" target="_blank" class="is-size-6 mt-3">Zubair Shafiq</a>
                </div>



            </div>
            <br>
            <p>To reach out, please email the corresponding author <a href="mailto:mharoon@ucdavis.edu"><strong>Muhammad Haroon</strong></a>.</p>
        </div>
    </article>

    <article class="section">
        <div class="container is-max-desktop">
            <h2 class="subtitle has-text-danger has-text-weight-bold">Citation</h2>
<pre><code>@article{doi:10.1073/pnas.2213020120,
    author   = {Muhammad Haroon  and Magdalena Wojcieszak  and Anshuman Chhabra  and Xin Liu  and Prasant Mohapatra  and Zubair Shafiq },
    title    = {Auditing YouTube’s recommendation system for ideologically congenial, extreme, and problematic recommendations},
    journal  = {Proceedings of the National Academy of Sciences},
    volume   = {120},
    number   = {50},
    pages    = {e2213020120},
    year     = {2023},
    doi      = {10.1073/pnas.2213020120},
    url      = {https://www.pnas.org/doi/abs/10.1073/pnas.2213020120},
    eprint   = {https://www.pnas.org/doi/pdf/10.1073/pnas.2213020120},
    abstract = {Algorithms of social media platforms are often criticized for recommending ideologically congenial and radical content to their users. Despite these concerns, evidence on such filter bubbles and rabbit holes of radicalization is inconclusive. We conduct an audit of the platform using 100,000 sock puppets that allow us to systematically and at scale isolate the influence of the algorithm in recommendations. We test 1) whether recommended videos are congenial with regard to users’ ideology, especially deeper in the watch trail and whether 2) recommendations deeper in the trail become progressively more extreme and come from problematic channels. We find that YouTube’s algorithm recommends congenial content to its partisan users, although some moderate and cross-cutting exposure is possible and that congenial recommendations increase deeper in the trail for right-leaning users. We do not find meaningful increases in ideological extremity of recommendations deeper in the trail, yet we show that a growing proportion of recommendations comes from channels categorized as problematic (e.g., “IDW,” “Alt-right,” “Conspiracy,” and “QAnon”), with this increase being most pronounced among the very-right users. Although the proportion of these problematic recommendations is low (max of 2.5%), they are still encountered by over 36.1% of users and up to 40% in the case of very-right users.}
}  
</code></pre>
        </div>
    </article>

    <footer class="footer has-background-white pb-3">
        <div class="container is-max-desktop has-text-centered">
            <img src="/img/ucdavis.png" />
        </div>
    </footer>

</body>

</html>